{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importing the Training Set\n",
    "------------------------\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I begin by importing useful packages, Numpy (for maths and arrays), and csv for reading and writing csv files.\n",
    "\n",
    "If I want to use something from this I need to call ```csv.[function]``` or ```np.[function]```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv as csv \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I check my working directory is pointing to the location of the training file, and then I open it in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\\\\\\\spf801\\\\staffusers$\\\\jsc\\\\Desktop\\\\Kaggle\\\\Titanic\\\\2. Python'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file_object = csv.reader(open('train.csv', 'rb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the ```next()``` command which skips the first line of headings. I create an empty list called ```data``` and then populate it with a line from the ```.csv``` file, before finally converting it to an array. Each item is a string by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = csv_file_object.next() \n",
    "                                 \n",
    "data=[]                          \n",
    "for row in csv_file_object:      \n",
    "    data.append(row)            \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '0' '3' ..., '7.25' '' 'S']\n",
      " ['2' '1' '1' ..., '71.2833' 'C85' 'C']\n",
      " ['3' '1' '3' ..., '7.925' '' 'S']\n",
      " ..., \n",
      " ['889' '0' '3' ..., '23.45' '' 'S']\n",
      " ['890' '1' '1' ..., '30' 'C148' 'C']\n",
      " ['891' '0' '3' ..., '7.75' '' 'Q']]\n"
     ]
    }
   ],
   "source": [
    "print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now pick out parts of the data starting with the headings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the first row of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '0' '3' 'Braund, Mr. Owen Harris' 'male' '22' '1' '0' 'A/5 21171'\n",
      " '7.25' '' 'S']\n"
     ]
    }
   ],
   "source": [
    "print data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the last row of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['891' '0' '3' 'Dooley, Mr. Patrick' 'male' '32' '0' '0' '370376' '7.75' ''\n",
      " 'Q']\n"
     ]
    }
   ],
   "source": [
    "print data[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And individual entries such as the 1st row, 4th column (remember indexing from zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Braund, Mr. Owen Harris\n"
     ]
    }
   ],
   "source": [
    "print data[0,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And can call a full gender column (Python starts indices from 0, not 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'female', 'female', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'female', 'female', 'female', 'male', 'male',\n",
       "       'female', 'female', 'male', 'male', 'female', 'female', 'male',\n",
       "       'male', 'female', 'male', 'female', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'female', 'female',\n",
       "       'male', 'female', 'female', 'male', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'male', 'female', 'male', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'female', 'female', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'female',\n",
       "       'male', 'female', 'female', 'male', 'male', 'female', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'female', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'female', 'female', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'female', 'female', 'female',\n",
       "       'female', 'female', 'male', 'male', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "       'female', 'male', 'female', 'female', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'female', 'female', 'female', 'male', 'female',\n",
       "       'male', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male', 'female', 'male', 'male', 'female', 'female',\n",
       "       'male', 'female', 'female', 'female', 'female', 'male', 'male',\n",
       "       'female', 'female', 'male', 'female', 'female', 'male', 'male',\n",
       "       'female', 'female', 'male', 'female', 'male', 'female', 'female',\n",
       "       'female', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'male', 'female', 'female', 'female', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'female', 'female',\n",
       "       'female', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "       'male', 'female', 'female', 'female', 'female', 'male', 'male',\n",
       "       'male', 'male', 'female', 'female', 'female', 'male', 'male',\n",
       "       'male', 'female', 'female', 'male', 'female', 'male', 'male',\n",
       "       'male', 'female', 'male', 'female', 'male', 'male', 'male',\n",
       "       'female', 'female', 'male', 'female', 'male', 'male', 'female',\n",
       "       'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'female', 'female', 'male', 'female', 'male', 'male',\n",
       "       'male', 'female', 'male', 'male', 'female', 'female', 'male',\n",
       "       'male', 'male', 'female', 'female', 'male', 'male', 'female',\n",
       "       'female', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'female', 'male', 'male', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'female', 'female', 'male', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'male', 'female', 'male', 'female', 'male', 'male', 'female',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'female', 'female', 'female', 'male', 'female', 'male',\n",
       "       'female', 'female', 'female', 'female', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'female', 'female', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "       'female', 'female', 'female', 'male', 'female', 'female', 'male',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'female', 'female', 'female', 'male', 'female',\n",
       "       'male', 'male', 'female', 'male', 'female', 'female', 'male',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female',\n",
       "       'male', 'male', 'female', 'male', 'male', 'female', 'female',\n",
       "       'male', 'female', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'female', 'male', 'female', 'female', 'male', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'female', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'male', 'female', 'male', 'female',\n",
       "       'male', 'male', 'male', 'male', 'male', 'female', 'female', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'female', 'female', 'male', 'male', 'male',\n",
       "       'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "       'female', 'female', 'female', 'male', 'male', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'female', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'female', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "       'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'female', 'female', 'female', 'male', 'female', 'male',\n",
       "       'male', 'male', 'female', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "       'female', 'male', 'male', 'male', 'female', 'female', 'male',\n",
       "       'female', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "       'male', 'male'], \n",
       "      dtype='|S82')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0::,4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```.csv``` reader works by default with strings, so I now need to convert to floats in order to do calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  1.,  3.,  1.,  3.,  3.,  1.,  3.,  3.,  2.,  3.,  1.,  3.,\n",
       "        3.,  3.,  2.,  3.,  2.,  3.,  3.,  2.,  2.,  3.,  1.,  3.,  3.,\n",
       "        3.,  1.,  3.,  3.,  1.,  1.,  3.,  2.,  1.,  1.,  3.,  3.,  3.,\n",
       "        3.,  3.,  2.,  3.,  2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "        1.,  2.,  1.,  1.,  2.,  3.,  2.,  3.,  3.,  1.,  1.,  3.,  1.,\n",
       "        3.,  2.,  3.,  3.,  3.,  2.,  3.,  2.,  3.,  3.,  3.,  3.,  3.,\n",
       "        2.,  3.,  3.,  3.,  3.,  1.,  2.,  3.,  3.,  3.,  1.,  3.,  3.,\n",
       "        3.,  1.,  3.,  3.,  3.,  1.,  1.,  2.,  2.,  3.,  3.,  1.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  1.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "        2.,  1.,  3.,  2.,  3.,  2.,  2.,  1.,  3.,  3.,  3.,  3.,  3.,\n",
       "        3.,  3.,  3.,  2.,  2.,  2.,  1.,  1.,  3.,  1.,  3.,  3.,  3.,\n",
       "        3.,  2.,  2.,  3.,  3.,  2.,  2.,  2.,  1.,  3.,  3.,  3.,  1.,\n",
       "        3.,  3.,  3.,  3.,  3.,  2.,  3.,  3.,  3.,  3.,  1.,  3.,  1.,\n",
       "        3.,  1.,  3.,  3.,  3.,  1.,  3.,  3.,  1.,  2.,  3.,  3.,  2.,\n",
       "        3.,  2.,  3.,  1.,  3.,  1.,  3.,  3.,  2.,  2.,  3.,  2.,  1.,\n",
       "        1.,  3.,  3.,  3.,  2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "        3.,  1.,  3.,  2.,  3.,  2.,  3.,  1.,  3.,  2.,  1.,  2.,  3.,\n",
       "        2.,  3.,  3.,  1.,  3.,  2.,  3.,  2.,  3.,  1.,  3.,  2.,  3.,\n",
       "        2.,  3.,  2.,  2.,  2.,  2.,  3.,  3.,  2.,  3.,  3.,  1.,  3.,\n",
       "        2.,  1.,  2.,  3.,  3.,  1.,  3.,  3.,  3.,  1.,  1.,  1.,  2.,\n",
       "        3.,  3.,  1.,  1.,  3.,  2.,  3.,  3.,  1.,  1.,  1.,  3.,  2.,\n",
       "        1.,  3.,  1.,  3.,  2.,  3.,  3.,  3.,  3.,  3.,  3.,  1.,  3.,\n",
       "        3.,  3.,  2.,  3.,  1.,  1.,  2.,  3.,  3.,  1.,  3.,  1.,  1.,\n",
       "        1.,  3.,  3.,  3.,  2.,  3.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,\n",
       "        2.,  3.,  2.,  3.,  2.,  2.,  1.,  1.,  3.,  3.,  2.,  2.,  3.,\n",
       "        1.,  3.,  2.,  3.,  1.,  3.,  1.,  1.,  3.,  1.,  3.,  1.,  1.,\n",
       "        3.,  1.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  3.,  3.,  3.,  3.,\n",
       "        1.,  3.,  3.,  3.,  3.,  1.,  2.,  3.,  3.,  3.,  2.,  3.,  3.,\n",
       "        3.,  3.,  1.,  3.,  3.,  1.,  1.,  3.,  3.,  1.,  3.,  1.,  3.,\n",
       "        1.,  3.,  3.,  1.,  3.,  3.,  1.,  3.,  2.,  3.,  2.,  3.,  2.,\n",
       "        1.,  3.,  3.,  1.,  3.,  3.,  3.,  2.,  2.,  2.,  3.,  3.,  3.,\n",
       "        3.,  3.,  2.,  3.,  2.,  3.,  3.,  3.,  3.,  1.,  2.,  3.,  3.,\n",
       "        2.,  2.,  2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  2.,  2.,  3.,\n",
       "        3.,  1.,  3.,  2.,  3.,  1.,  1.,  3.,  2.,  1.,  2.,  2.,  3.,\n",
       "        3.,  2.,  3.,  1.,  2.,  1.,  3.,  1.,  2.,  3.,  1.,  1.,  3.,\n",
       "        3.,  1.,  1.,  2.,  3.,  1.,  3.,  1.,  2.,  3.,  3.,  2.,  1.,\n",
       "        3.,  3.,  3.,  3.,  2.,  2.,  3.,  1.,  2.,  3.,  3.,  3.,  3.,\n",
       "        2.,  3.,  3.,  1.,  3.,  1.,  1.,  3.,  3.,  3.,  3.,  1.,  1.,\n",
       "        3.,  3.,  1.,  3.,  1.,  3.,  3.,  3.,  3.,  3.,  1.,  1.,  2.,\n",
       "        1.,  3.,  3.,  3.,  3.,  1.,  1.,  3.,  1.,  2.,  3.,  2.,  3.,\n",
       "        1.,  3.,  3.,  1.,  3.,  3.,  2.,  1.,  3.,  2.,  2.,  3.,  3.,\n",
       "        3.,  3.,  2.,  1.,  1.,  3.,  1.,  1.,  3.,  3.,  2.,  1.,  1.,\n",
       "        2.,  2.,  3.,  2.,  1.,  2.,  3.,  3.,  3.,  1.,  1.,  1.,  1.,\n",
       "        3.,  3.,  3.,  2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  2.,  1.,\n",
       "        1.,  3.,  3.,  3.,  2.,  1.,  3.,  3.,  2.,  1.,  2.,  1.,  3.,\n",
       "        1.,  2.,  1.,  3.,  3.,  3.,  1.,  3.,  3.,  2.,  3.,  2.,  3.,\n",
       "        3.,  1.,  2.,  3.,  1.,  3.,  1.,  3.,  3.,  1.,  2.,  1.,  3.,\n",
       "        3.,  3.,  3.,  3.,  2.,  3.,  3.,  2.,  2.,  3.,  1.,  3.,  3.,\n",
       "        3.,  1.,  2.,  1.,  3.,  3.,  1.,  3.,  1.,  1.,  3.,  2.,  3.,\n",
       "        2.,  3.,  3.,  3.,  1.,  3.,  3.,  3.,  1.,  3.,  1.,  3.,  3.,\n",
       "        3.,  2.,  3.,  3.,  3.,  2.,  3.,  3.,  2.,  1.,  1.,  3.,  1.,\n",
       "        3.,  3.,  2.,  2.,  3.,  3.,  1.,  2.,  1.,  2.,  2.,  2.,  3.,\n",
       "        3.,  3.,  3.,  1.,  3.,  1.,  3.,  3.,  2.,  2.,  3.,  3.,  3.,\n",
       "        1.,  1.,  3.,  3.,  3.,  1.,  2.,  3.,  3.,  1.,  3.,  1.,  1.,\n",
       "        3.,  3.,  3.,  2.,  2.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  2.,\n",
       "        3.,  1.,  2.,  3.,  3.,  2.,  3.,  2.,  2.,  1.,  3.,  2.,  3.,\n",
       "        2.,  3.,  1.,  3.,  2.,  2.,  2.,  3.,  3.,  1.,  3.,  3.,  1.,\n",
       "        1.,  1.,  3.,  3.,  1.,  3.,  2.,  1.,  3.,  2.,  3.,  3.,  3.,\n",
       "        2.,  2.,  3.,  2.,  3.,  1.,  3.,  3.,  3.,  1.,  3.,  1.,  1.,\n",
       "        3.,  3.,  3.,  3.,  3.,  2.,  3.,  2.,  3.,  3.,  3.,  3.,  1.,\n",
       "        3.,  1.,  1.,  3.,  3.,  3.,  3.,  3.,  3.,  1.,  3.,  2.,  3.,\n",
       "        1.,  3.,  2.,  1.,  3.,  3.,  3.,  2.,  2.,  1.,  3.,  3.,  3.,\n",
       "        1.,  3.,  2.,  1.,  3.,  3.,  2.,  3.,  3.,  1.,  3.,  2.,  3.,\n",
       "        3.,  1.,  3.,  1.,  3.,  3.,  3.,  3.,  2.,  3.,  1.,  3.,  2.,\n",
       "        3.,  3.,  3.,  1.,  3.,  3.,  3.,  1.,  3.,  2.,  1.,  3.,  3.,\n",
       "        3.,  3.,  3.,  2.,  1.,  3.,  3.,  3.,  1.,  2.,  3.,  1.,  1.,\n",
       "        3.,  3.,  3.,  2.,  1.,  3.,  2.,  2.,  2.,  1.,  3.,  3.,  3.,\n",
       "        1.,  1.,  3.,  2.,  3.,  3.,  3.,  3.,  1.,  2.,  3.,  3.,  2.,\n",
       "        3.,  3.,  2.,  1.,  3.,  1.,  3.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0::,2].astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can use the ```size()``` function to count elements and ```sum()``` to count up elements (used as indicator functions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I look at the second column, and the size function counts total passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_passengers = np.size(data[0::,1].astype(np.float)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,  I use the sum function which will only count those who survived (and given the value 1, not 0) in order to count the survivors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_survived = np.sum(data[0::,1].astype(np.float)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, I count the proportion of survivors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.383838383838\n"
     ]
    }
   ],
   "source": [
    "proportion_survivors = number_survived / number_passengers\n",
    "print proportion_survivors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Gender Analysis\n",
    "------------------------\n",
    "------------\n",
    "\n",
    "I now concetrate on those rows which concern females -  the elements in the gender column that equals “female”, or the men (\"not female\"), and can directly apply a filter to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "women_only_stats = data[0::,4] == \"female\"\n",
    "men_only_stats = data[0::,4] != \"female\"                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use these two new variables as a \"mask\" on our original training data, so we can select only those women, and only those men on board, then calculate the proportion of those who survived. We play the same trick on the survivial column of comparing the total (size of set), with sum (adds 1 for each survivor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of women who survived is 0.742038216561\n",
      "Proportion of men who survived is 0.188908145581\n"
     ]
    }
   ],
   "source": [
    "women_onboard = data[women_only_stats,1].astype(np.float)     \n",
    "men_onboard = data[men_only_stats,1].astype(np.float)\n",
    "\n",
    "proportion_women_survived = np.sum(women_onboard) / np.size(women_onboard)  \n",
    "proportion_men_survived = np.sum(men_onboard) / np.size(men_onboard) \n",
    "\n",
    "print 'Proportion of women who survived is %s' % proportion_women_survived\n",
    "print 'Proportion of men who survived is %s' % proportion_men_survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Women were much more likely to survive, and the first model I build, as a prediction for which of the remaining passengers will survive is simply that women survive and men die. Of course, there will be other, possibly more presuasive factors (or combinations of factors which we look into later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We now begin work on creating a prediction file. So we import the data set again, and create a .csv file which will have our predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_file = open('test.csv', 'rb')\n",
    "test_file_object = csv.reader(test_file)\n",
    "header = test_file_object.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_file = open(\"ModelBasedonGenderAlone.csv\", \"wb\")\n",
    "prediction_file_object = csv.writer(prediction_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to read in the test file row by row, see if it is female or male, and write our survival prediction (women assigned a 1; men assigned 0) to a new file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_file_object.writerow([\"PassengerId\", \"Survived\"])\n",
    "for row in test_file_object:       \n",
    "    if row[3] == 'female':                                        \n",
    "        prediction_file_object.writerow([row[0],'1'])   \n",
    "    else:                                 \n",
    "        prediction_file_object.writerow([row[0],'0'])    \n",
    "test_file.close()\n",
    "prediction_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the immediate advantages of using Python over Excel is that we can can quickly run all of the steps again in the future, for a different training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Class, Gender, and Ticket Price Analysis\n",
    "------------------------\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I begin by checking that the data is still available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '0' '3' 'Braund, Mr. Owen Harris' 'male' '22' '1' '0' 'A/5 21171'\n",
      " '7.25' '' 'S']\n"
     ]
    }
   ],
   "source": [
    "print data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will analyse according to gender (male/female), boarding class (1st/2nd/3rd), and ticket price (which I'll group into 4 bins). I want to take the ticket prices as 0-10, 10-20, 20-30, 30+, but as I will create bins of equal width I begin by making all the top prices fall into the 30-40 bin (setting tickets more than 40 as 39 WLOG). This may be described as adding a ceiling to our ticket price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fare_ceiling = 40\n",
    "data[ data[0::,9].astype(np.float) >= fare_ceiling, 9 ] = fare_ceiling - 1.0 #set to be 39 in top bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for price in data[0::, 9]:\n",
    "    if price.astype(np.float) > 40:\n",
    "        print(\"ceiling not implemented\", price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing has executed so the ceiling has worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fare_bracket_size = 10\n",
    "number_of_price_brackets = fare_ceiling / fare_bracket_size #We have 4 buckets described above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 3 classes on board - 1st, 2nd and 3rd - but without this knowlede I can calculate this from the data directly, by taking the the length of the array of UNIQUE values in the column of index 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "number_of_classes = len(np.unique(data[0::,2])) \n",
    "print number_of_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now build a survival table (filled with zeros for now), ready to populate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_genders = 2\n",
    "survival_table = np.zeros((number_of_genders, number_of_classes, number_of_price_brackets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now loop through each variable and find all those passengers that agree with the statements. We loop through each class, loop through each price bin, use compound logic, use the bins for fares between $10j$ and $10(j+1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(number_of_classes):      \n",
    "  for j in xrange(number_of_price_brackets):   \n",
    "\n",
    "    women_only_stats = data[                          \n",
    "                       (data[0::,4] == \"female\")    \n",
    "                       &(data[0::,2].astype(np.float) \n",
    "                             == i+1)                      \n",
    "                       &(data[0:,9].astype(np.float)   \n",
    "                            >= j*fare_bracket_size)               \n",
    "                       &(data[0:,9].astype(np.float)  \n",
    "                            < (j+1)*fare_bracket_size)    \n",
    "                          , 1]                         \n",
    "\n",
    "\n",
    "    men_only_stats = data[                                       \n",
    "                         (data[0::,4] != \"female\")    \n",
    "                       &(data[0::,2].astype(np.float) \n",
    "                             == i+1)                                       \n",
    "                       &(data[0:,9].astype(np.float)   \n",
    "                            >= j*fare_bracket_size)                 \n",
    "                       &(data[0:,9].astype(np.float)  \n",
    "                            < (j+1)*fare_bracket_size)    \n",
    "                          , 1] \n",
    "    survival_table[0,i,j] = np.mean(women_only_stats.astype(np.float)) \n",
    "    survival_table[1,i,j] = np.mean(men_only_stats.astype(np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is hidden by the functions we are testing for, but ```data[ where function, 1]``` means it is finding the Survived column for the conditional criteria which is being called. As the loop starts with i=0 and j=0, the first loop will return the Survived values for all the 1st-class females ```(i + 1)``` who paid less than ```10 ((j+1)*fare_bracket_size)``` and similarly all the 1st-class males who paid less than 10.  Before resetting to the top of the loop, we can calculate the proportion of survivors for this particular combination of criteria and record it to our survival table.\n",
    "\n",
    "The nasty warning occurs because some categories were empty, but we can set them to 0 using the following statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survival_table[ survival_table != survival_table ] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.          0.          0.83333333  0.97727273]\n",
      "  [ 0.          0.91428571  0.9         1.        ]\n",
      "  [ 0.59375     0.58139535  0.33333333  0.125     ]]\n",
      "\n",
      " [[ 0.          0.          0.4         0.38372093]\n",
      "  [ 0.          0.15873016  0.16        0.21428571]\n",
      "  [ 0.11153846  0.23684211  0.125       0.24      ]]]\n"
     ]
    }
   ],
   "source": [
    "print survival_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these numbers is the proportion of survivors for that criteria of passengers. \n",
    "\n",
    "For example, 0.91428571 signifies 91.4% of female, Pclass = 2, in the Fare bin of 10-19. For our second iteration of a model, let's again assume any probability greater than or equal to 0.5 should result in our predicting survival -- and less than 0.5 should not. We can update our survival table with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survival_table[ survival_table < 0.5 ] = 0\n",
    "survival_table[ survival_table >= 0.5 ] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  1.  1.]\n",
      "  [ 0.  1.  1.  1.]\n",
      "  [ 1.  1.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "print survival_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we go through each row of the test file we can find what criteria fit each new passenger and assign them a 1 or 0 according to our survival table.  As previously, let's open up the test file to read (and skip the header row), and also a new file to write to, called 'genderclassmodel.csv':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_file = open('test.csv', 'rb')\n",
    "test_file_object = csv.reader(test_file)\n",
    "header = test_file_object.next()\n",
    "predictions_file = open(\"ModelBasedonGenderClass.csv\", \"wb\")\n",
    "predictions_file_object = csv.writer(predictions_file)\n",
    "predictions_file_object.writerow([\"PassengerId\", \"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the previous model, we can take the first passenger, look at his/her gender, class, and price of ticket, and assign a Survived label. However, not every passenger in the test.csv file is not binned. We should loop through each bin and see if the price of their ticket falls in that bin. If so, we can break the loop (so we don’t go through all the bins) and assign that bin.\n",
    "\n",
    "A way to test for existence of a fare is to try to make it into a float, since, in the case of empty data, the script cannot make it a float. \n",
    "\n",
    "If there is no fare entry we'll assume a fare bin simply correlated to the Passenger class. For example, if the passenger is third class they are put in the first bin ($0-9), second class into the second bin ($10-19), etc. The other thing to notice is that we assign the bin_fare to equal ```3-Pclass```. Although there are four bins, they must go from 0 to 3 because we will be using these as indices of our survival table. This little loop determines the index of the bin to look up in the survival table.\n",
    "\n",
    "Now that we have determined the binned ticket price (bin_fare), we can see if the passenger is female (row[3]), find their Pclass (row[1]), and then grab the relevant element in survival_table. We need to convert this from the float in the survival_table into an integer (int) that we write in our prediction file for Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsc\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:24: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\jsc\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:22: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "for row in test_file_object:                 # We are going to loop\n",
    "                                              # through each passenger\n",
    "                                              # in the test set                     \n",
    "  for j in xrange(number_of_price_brackets):  # For each passenger we\n",
    "                                              # loop through each price bin\n",
    "    try:                                      # Some passengers have no\n",
    "                                              # Fare data so try to make\n",
    "      row[8] = float(row[8])                  # a float\n",
    "    except:                                   # If fails: no data, so \n",
    "      bin_fare = 3 - float(row[1])            # bin the fare according Pclass\n",
    "      break                                   # Break from the loop\n",
    "    if row[8] > fare_ceiling:              # If there is data see if\n",
    "                                              # it is greater than fare\n",
    "                                              # ceiling we set earlier\n",
    "      bin_fare = number_of_price_brackets-1   # If so set to highest bin\n",
    "      break                                   # And then break loop\n",
    "    if row[8] >= j * fare_bracket_size\\\n",
    "       and row[8] < \\\n",
    "       (j+1) * fare_bracket_size:             # If passed these tests \n",
    "                                              # then loop through each bin \n",
    "      bin_fare = j                            # then assign index\n",
    "      break  \n",
    "  if row[3] == 'female':\n",
    "    predictions_file_object.writerow([row[0], \"%d\" % int(survival_table[ 0, float(row[1]) - 1, bin_fare])])\n",
    "  else:\n",
    "    predictions_file_object.writerow([row[0], \"%d\" % int(survival_table[ 1, float(row[1]) - 1, bin_fare])])\n",
    "# Close out the files\n",
    "test_file.close()\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now inserted a 1 or 0 prediction, according to gender, class, and how much she/he paid in fare. We can now submit the file genderclassmodel.csv.\n",
    "\n",
    "Just like in Excel, here we built predictions that take into account several features. But type  print survival_table  again: what do you notice about the predictions for men? Surely some of the men survived, but our model can only predict 0. This suggests one source of error that's reflected in our leaderboard score, and it may already be prompting new ideas for improving your next model. \n",
    "\n",
    "Yet in contrast to Excel, we have created a script now that can easily be altered to add more variables. For example, we could include Age, where they Embarked, or even their Name. All these variables may themselves have complications, so you will need to think of ways to make them useful. In this tutorial, in order to fill in any missing values of the fare, we assumed the Passenger Class can correlate simply to which fare bin to use. Using python we developed an extensible model without too much effort.\n",
    "\n",
    "We are almost ready to apply Machine Learning on this data using python. However before we jump in, it would be advantageous to take a brief detour to learn tools that makes some of the work here easier.\n",
    "\n",
    "Next, I will explore python's Pandas package."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
